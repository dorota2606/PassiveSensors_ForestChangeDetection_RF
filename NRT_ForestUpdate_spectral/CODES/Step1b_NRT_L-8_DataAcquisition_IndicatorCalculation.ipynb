{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cfb7b8-4f5d-486f-9393-24bff8466373",
   "metadata": {},
   "source": [
    "# Data search and calculation of spectral indices for subareas - Landsat-8\n",
    "## 1) Search full coverage for designated subarase\n",
    "\n",
    "    This code searches for Landsat-8 satellite images covering specific geographic areas within a given time frame and cloud cover limit, then generates a heatmap visualizing the number of image sets that fully cover each area.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ace083-a648-4f76-9d62-ae23ea33eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eodag import EODataAccessGateway\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from datetime import timedelta\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def parse_date(image_title):\n",
    "    date_str = image_title.split('_')[3]  # If the format is \"LC08_L2SP_190056_20151217_02_T1\"\n",
    "    return datetime.strptime(date_str, '%Y%m%d')\n",
    "\n",
    "# Paths \n",
    "subareas_path = '/path/to/area_boundaries/subareas_clip_to_AOI0_4326.shp'  # subareas for searching \n",
    "tiles_path = '/path/to/area_boundaries/subareas_4326.shp'  # base for the heatmap\n",
    "txt_path = '/path/to/text_file_location/textfile.txt'\n",
    "heatmap_path = '/path/to/heatmap_save_location/heatmap.png'\n",
    "\n",
    "subareas_data = gpd.read_file(subareas_path)\n",
    "tiles_data = gpd.read_file(tiles_path)\n",
    "\n",
    "cloud_cover = 25\n",
    "start = \"2019-01-01\"\n",
    "end = \"2019-01-31\"\n",
    "provider = 'planetary_computer'\n",
    "\n",
    "dag = EODataAccessGateway()\n",
    "product_type = 'LANDSAT_C2L2'\n",
    "\n",
    "def set_preferred_provider(self, provider):\n",
    "    if provider not in self.available_providers():\n",
    "        raise UnsupportedProvider(\n",
    "            f\"This provider is not recognised by eodag: {provider}\"\n",
    "        )\n",
    "    preferred_provider, max_priority = self.get_preferred_provider()\n",
    "    if preferred_provider != provider:\n",
    "        new_priority = max_priority + 1\n",
    "        self._plugins_manager.set_priority(provider, new_priority)\n",
    "\n",
    "dag.set_preferred_provider(provider)\n",
    "\n",
    "tile_coverage_sets = defaultdict(int)\n",
    "coverage_results = defaultdict(list)\n",
    "\n",
    "for _, row in subareas_data.iterrows():\n",
    "    selected_tile_name = row['layer']\n",
    "    tile_geometry = row.geometry\n",
    "    print(f\"Processing tile: {selected_tile_name}\")\n",
    "    search_results = dag.search_all(productType=product_type, geom=tile_geometry, start=start, end=end, cloudCover=cloud_cover)\n",
    "\n",
    "    images_by_date = defaultdict(list)\n",
    "    for product in search_results:\n",
    "        image_date = parse_date(product.properties['title'])\n",
    "        images_by_date[image_date].append(product)\n",
    "\n",
    "    full_coverage_found = False\n",
    "\n",
    "    for date, products in images_by_date.items():\n",
    "        for product in products:\n",
    "            product_geometry = shape(product.geometry)\n",
    "            if product_geometry.contains(tile_geometry):\n",
    "                print(f\"Full coverage found with single image: {product.properties['title']}\")\n",
    "                coverage_results[selected_tile_name].append(product.properties['title'])\n",
    "                full_coverage_found = True\n",
    "                tile_coverage_sets[selected_tile_name] += 1\n",
    "                break\n",
    "        if full_coverage_found:\n",
    "            break\n",
    "\n",
    "    used_products = set() \n",
    "\n",
    "    if not full_coverage_found:\n",
    "        unique_products = list({product.properties['title']: product for product in search_results}.values())\n",
    "        \n",
    "        for r in range(2, min(4, len(unique_products) + 1)):\n",
    "            for combo in combinations(unique_products, r):\n",
    "                dates = [parse_date(p.properties['title']) for p in combo]\n",
    "                max_date_diff = (max(dates) - min(dates)).days\n",
    "                \n",
    "                if max_date_diff <= 16:\n",
    "                    combined_geometry = unary_union([shape(p.geometry) for p in combo])\n",
    "                    \n",
    "                    if combined_geometry.contains(tile_geometry):\n",
    "                        print(f\"Full coverage found with images: {[p.properties['title'] for p in combo]}\")\n",
    "                        coverage_results[selected_tile_name] = [p.properties['title'] for p in combo]\n",
    "                        tile_coverage_sets[selected_tile_name] = 1\n",
    "                        full_coverage_found = True\n",
    "                        break\n",
    "            if full_coverage_found:\n",
    "                break\n",
    "\n",
    "unique_dates_per_tile = defaultdict(set)\n",
    "for tile, titles in coverage_results.items():\n",
    "    for title in titles:\n",
    "        date_of_image = parse_date(title)\n",
    "        unique_dates_per_tile[tile].add(date_of_image)\n",
    "\n",
    "with open(txt_path, 'w') as file:\n",
    "    for tile, dates in unique_dates_per_tile.items():\n",
    "        file.write(f\"{tile}: 1 unique image set\\n\")\n",
    "        for date in sorted(dates):\n",
    "            date_str = date.strftime('%Y %m %d')\n",
    "            titles = [title for title in coverage_results[tile] if parse_date(title) == date]\n",
    "            file.write(f\"  Image ({date_str}): {' - '.join(titles)}\\n\")\n",
    "\n",
    "tiles_data['num_images'] = tiles_data['layer'].map(tile_coverage_sets).fillna(0)\n",
    "num_images_bins = list(range(11)) \n",
    "norm = BoundaryNorm(num_images_bins, ncolors=len(num_images_bins) - 1, clip=True)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "heatmap = tiles_data.plot(column='num_images', ax=ax, cmap='GnBu', edgecolor='black', vmin=0, vmax=10)\n",
    "subareas_data.boundary.plot(ax=ax, color='black')\n",
    "\n",
    "for idx, row in tiles_data.iterrows():\n",
    "    plt.annotate(text=f\"{int(row['num_images'])}\", xy=(row.geometry.centroid.x, row.geometry.centroid.y),\n",
    "                 horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.text(0.5, 1.05, f\"Landsat-8 Search Period: {start} to {end}\", \n",
    "         ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "cbar = fig.colorbar(heatmap.collections[0], ax=ax, extend='neither')\n",
    "cbar.set_label('Number of image sets')\n",
    "cbar.set_ticks(range(0, 11)) \n",
    "\n",
    "plt.savefig(heatmap_path, dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad139a55-9aee-46f0-aad2-3c4e8d939cda",
   "metadata": {},
   "source": [
    "## 2) Download the images\n",
    "\r",
    "    \n",
    "This code searches for and downloads unique Landsat 8 imagery IDs from a specified text file, using EODataAccessGateway (EODAG) to interface with a preferred data provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfa34a-07cb-4fd4-a07d-0c4d1ec87af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from eodag import EODataAccessGateway\n",
    "import re\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "dag = EODataAccessGateway()\n",
    "\n",
    "file_path = '/path/to/text_file_location/textfile.txt'\n",
    "\n",
    "unique_image_ids = set()\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        match = re.search(r'(LC08_L2SP_\\d+_\\d{8}_02_T1)', line)\n",
    "        if match:\n",
    "            unique_image_ids.add(match.group(1))\n",
    "\n",
    "output_directory = '/path/to/save_L-8_data'\n",
    "DEFAULT_DOWNLOAD_WAIT = 2\n",
    "DEFAULT_DOWNLOAD_TIMEOUT = 50\n",
    "\n",
    "dag.set_preferred_provider('planetary_computer')\n",
    "\n",
    "for image_id in unique_image_ids:\n",
    "    search_criteria = {\n",
    "        \"productType\": \"LANDSAT_C2L2\",\n",
    "        \"id\": image_id\n",
    "    }\n",
    "    search_results, _ = dag.search(**search_criteria) \n",
    "\n",
    "    for result in search_results: \n",
    "        try:\n",
    "            downloaded_path = result.download(\n",
    "                progress_callback=None,\n",
    "                wait=DEFAULT_DOWNLOAD_WAIT,\n",
    "                timeout=DEFAULT_DOWNLOAD_TIMEOUT,\n",
    "                outputs_prefix=output_directory)\n",
    "            print(f\"Downloaded: {downloaded_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb5326-b7e4-4cc1-94d3-ea4e35566573",
   "metadata": {},
   "source": [
    "## 3) Resampling\n",
    "\n",
    "    \r\n",
    "This code resamples Landsat 8 raster images to match the resolution and alignment of a reference image, saving the resampled images with preserved folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660761e-40ef-437a-935a-401455b3e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "import gc\n",
    "\n",
    "input_base_folder = r'/path/to/L-8_data'\n",
    "output_base_folder = r'/path/to/save_L-8_data_resampled'\n",
    "reference_image_path = r'/path/to/reference_image.tif'\n",
    "\n",
    "os.makedirs(output_base_folder, exist_ok=True)\n",
    "\n",
    "reference_image = rioxarray.open_rasterio(reference_image_path)\n",
    "\n",
    "def resample_image(input_path, output_base_folder, reference_image, nodata_value= np.nan):\n",
    "    # Calculate the output path while preserving the folder structure\n",
    "    relative_path = os.path.relpath(input_path, input_base_folder)\n",
    "    output_path = os.path.join(output_base_folder, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    input_image = rioxarray.open_rasterio(input_path)\n",
    "    input_image = input_image.astype(\"float32\")\n",
    "    input_image.rio.write_nodata(nodata_value, inplace=True)\n",
    "    resampled_image = input_image.rio.reproject_match(reference_image, resampling=Resampling.bilinear)\n",
    "    \n",
    "    resampled_image.rio.to_raster(output_path)\n",
    "    gc.collect()\n",
    "\n",
    "for root, _, files in os.walk(input_base_folder):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".TIF\"):\n",
    "            input_path = os.path.join(root, file_name)\n",
    "            resample_image(input_path, output_base_folder, reference_image)\n",
    "\n",
    "print(f\"Resampling completed. Resampled images saved in: {output_base_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f8426-6a22-41c3-92e9-fb9901c9abb1",
   "metadata": {},
   "source": [
    "## 4) Calculation of spectral indices\n",
    "\n",
    "    This code automates the processing of Landsat 8 satellite imagery by clipping, merging, and calculating various spectral indices for areas of interest defined in a shapefile, based on configurations specified in a text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487e95c-d8c5-41a4-b3f3-a1ee430ee32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "\n",
    "shp_file = '/path/to/area_boundaries/subareas_clip_to_AOI0_4326.shp'\n",
    "txt_file = '/path/to/text_file_location/textfile.txt'\n",
    "output_base_folder = '/path/to/output_files_save_location/landsat8'\n",
    "base_folder = '/path/to/L-8_data_resampled'\n",
    "\n",
    "def generate_image_paths(txt_file, base_folder):\n",
    "    image_paths = {}\n",
    "    with open(txt_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    current_aoi = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('AOI'):\n",
    "            current_aoi = line.split(':')[0].strip()\n",
    "            image_paths[current_aoi] = []\n",
    "        elif line.startswith('Image'):\n",
    "            if current_aoi:\n",
    "                parts = line.split(':')\n",
    "                if len(parts) == 2:\n",
    "                    image_id = parts[1].strip()\n",
    "                    image_name = image_id.split(':')[-1].strip()\n",
    "                    image_path = os.path.join(base_folder, image_name)\n",
    "                    image_paths[current_aoi].append({'path': image_path, 'bands': {}})\n",
    "                else:\n",
    "                    print(f\"Invalid line format: {line}\")\n",
    "            else:\n",
    "                print(\"AOI name not found.\")\n",
    "                continue\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def find_tif_files_for_bands(image_paths):\n",
    "    for aoi, images in image_paths.items():\n",
    "        for image in images:\n",
    "            image_path = image['path']\n",
    "            band_paths = {\"B2\": None, \"B3\": None, \"B4\": None, \"B5\": None, \"B6\": None, \"B7\": None}\n",
    "            for root, dirs, files in os.walk(image_path):\n",
    "                for file in files:\n",
    "                    if file.upper().endswith(\".TIF\"):\n",
    "                        for band in band_paths.keys():\n",
    "                            band_pattern = f\"_SR_{band}.TIF\"\n",
    "                            if band_pattern in file.upper():\n",
    "                                band_paths[band] = os.path.join(root, file)\n",
    "            image['bands'] = band_paths\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "# CLIPPING SPECTRAL BANDS TO SUBAREA BOUNDARIES                  \n",
    "def get_subarea_bounds(shp_file, subarea):\n",
    "    gdf = gpd.read_file(shp_file)\n",
    "    subarea_geom = gdf.loc[gdf['layer'] == subarea, 'geometry'].unary_union\n",
    "    return subarea_geom\n",
    "\n",
    "def extract_date_from_image_name(image_name):\n",
    "    date_str = re.search(r'\\d{8}', image_name).group()\n",
    "    return datetime.datetime.strptime(date_str, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "\n",
    "def clip_raster_to_aoi(image_path, bounds, output_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        out_image, out_transform = mask(src, shapes=[bounds], crop=True)\n",
    "        out_meta = src.meta.copy()\n",
    "\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "\n",
    "        with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "def process_and_clip_images(image_paths, shp_file, output_base_folder):\n",
    "    for aoi, images in image_paths.items():\n",
    "        aoi_folder = os.path.join(output_base_folder, aoi)\n",
    "        if not os.path.exists(aoi_folder):\n",
    "            os.makedirs(aoi_folder)\n",
    "        \n",
    "        for image in images:\n",
    "            date = extract_date_from_image_name(os.path.basename(image['path']))\n",
    "            date_folder = os.path.join(aoi_folder, f\"{aoi}_{date}\")\n",
    "            if not os.path.exists(date_folder):\n",
    "                os.makedirs(date_folder)\n",
    "\n",
    "            bounds = get_subarea_bounds(shp_file, aoi)\n",
    "\n",
    "            for band, band_path in image['bands'].items():\n",
    "                if band_path:\n",
    "                    output_path = os.path.join(date_folder, f\"{band}_{date}.tif\")\n",
    "                    clip_raster_to_aoi(band_path, bounds, output_path)\n",
    "\n",
    "def merge_images_with_rasterio(image_paths, output_path):\n",
    "    src_files_to_mosaic = []\n",
    "    for path in image_paths:\n",
    "        src = rasterio.open(path)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": mosaic.shape[1],\n",
    "                     \"width\": mosaic.shape[2],\n",
    "                     \"transform\": out_trans,\n",
    "                     \"crs\": src.crs})\n",
    "\n",
    "    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "\n",
    "# CALCULATING SPECTRAL INDICES\n",
    "def calculate_all_indices_landsat(output_folder, red_path, nir_path, green_path, blue_path, swir1_path, swir2_path, date, aoi):\n",
    "    with rasterio.open(red_path) as red_src, \\\n",
    "         rasterio.open(nir_path) as nir_src, \\\n",
    "         rasterio.open(green_path) as green_src, \\\n",
    "         rasterio.open(blue_path) as blue_src, \\\n",
    "         rasterio.open(swir1_path) as swir1_src, \\\n",
    "         rasterio.open(swir2_path) as swir2_src:\n",
    "\n",
    "        red = red_src.read(1, masked=True).astype('float32') / 65535.0\n",
    "        nir = nir_src.read(1, masked=True).astype('float32') / 65535.0\n",
    "        green = green_src.read(1, masked=True).astype('float32') / 65535.0\n",
    "        blue = blue_src.read(1, masked=True).astype('float32') / 65535.0\n",
    "        swir1 = swir1_src.read(1, masked=True).astype('float32') / 65535.0\n",
    "        swir2 = swir2_src.read(1, masked=True).astype('float32') / 65535.0\n",
    "    \n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "        red[red == 0] = np.nan\n",
    "        nir[nir == 0] = np.nan\n",
    "        green[green == 0] = np.nan\n",
    "        blue[blue == 0] = np.nan\n",
    "        swir1[swir1 == 0] = np.nan\n",
    "        swir2[swir2 == 0] = np.nan    \n",
    "\n",
    "        ndvi = (nir - red) / (nir + red)\n",
    "        gndvi = (nir - green) / (nir + green)\n",
    "        evi = 2.5 * ((nir - red) / (nir + 6 * red - 7.5 * blue + 1))\n",
    "        savi = (1 + 0.5) * ((nir - red) / (nir + red + 0.5)) \n",
    "        osavi = ((nir - red) / (nir + red + 0.16))\n",
    "        dvi = nir - red\n",
    "        sr = red / nir\n",
    "        gemi = ((2 * (nir ** 2 - red ** 2) + 1.5 * nir + 0.5 * red) / (nir + red + 0.5)) * (1 - 0.25 * ((2 * (nir ** 2 - red ** 2) + 1.5 * nir + 0.5 * red) / (nir + red + 0.5))) - ((red - 0.125) / (1 - nir))\n",
    "        ndwi = (green - nir) / (green + nir)\n",
    "        mndwi = (green - swir1) / (green + swir1)\n",
    "        lswi = (nir - swir1) / (nir + swir1)\n",
    "        ui = (swir2 - nir) / (swir2 + nir)\n",
    "        ndbi = (swir1 - nir) / (swir1 + nir)\n",
    "        mndbi = (swir2 - blue) / (swir2 + blue)      \n",
    "        bsi = ((red + swir1) - (nir + blue)) / ((red + swir1) + (nir + blue))                                                                          \n",
    "\n",
    "        indices = {\"NDVI\": ndvi, \"GNDVI\": gndvi, \"EVI\": evi, \"SAVI\": savi, \"OSAVI\": osavi, \"DVI\": dvi, \"SR\": sr, \"GEMI\": gemi, \"NDWI\": ndwi, \"BSI\": bsi, \"MNDBI\": mndbi, \"LSWI\": lswi, \"MNDWI\": mndwi, \"NDBI\": ndbi, \"UI\": ui}\n",
    "\n",
    "        for index_name, index_data in indices.items():\n",
    "            output_file = os.path.join(output_folder, f\"L8_{aoi}_{index_name}_{date}.tif\")\n",
    "\n",
    "            with rasterio.open(output_file, 'w', driver='GTiff', width=red.shape[1], height=red.shape[0], count=1, dtype=str(index_data.dtype), crs=red_src.crs, transform=red_src.transform) as dst:\n",
    "                dst.write(index_data, 1)\n",
    "\n",
    "# PROCESSING\n",
    "def process_area_bands_landsat(image_paths, shp_file, output_base_folder):\n",
    "    \n",
    "    for aoi, images in image_paths.items():\n",
    "        dates = [extract_date_from_image_name(os.path.basename(image['path'])) for image in images]\n",
    "        dates.sort()\n",
    "        \n",
    "        if len(dates) > 1:\n",
    "            date_range = f\"{dates[0]}_{dates[-1]}\"\n",
    "        else:\n",
    "            date_range = dates[0]\n",
    "        \n",
    "        aoi_folder = os.path.join(output_base_folder, f\"{aoi}_{date_range}\")\n",
    "        if not os.path.exists(aoi_folder):\n",
    "            os.makedirs(aoi_folder)\n",
    "        \n",
    "        all_bands_paths = {band: [] for band in [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]}\n",
    "\n",
    "        for image in images:\n",
    "            date = extract_date_from_image_name(os.path.basename(image['path']))\n",
    "            bounds = get_subarea_bounds(shp_file, aoi)\n",
    "\n",
    "            for band, band_path in image['bands'].items():\n",
    "                if band_path:\n",
    "                    output_path = os.path.join(aoi_folder, f\"{band}_{date}.tif\")\n",
    "                    clip_raster_to_aoi(band_path, bounds, output_path)\n",
    "                    all_bands_paths[band].append(output_path)\n",
    "\n",
    "        if len(set(dates)) > 1:\n",
    "            for band, paths in all_bands_paths.items():\n",
    "                merged_output_path = os.path.join(aoi_folder, f\"{band}_merged.tif\")\n",
    "                merge_images_with_rasterio(paths, merged_output_path)\n",
    "                all_bands_paths[band] = [merged_output_path]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # If all necessary bands are present, calculate spectral indices\n",
    "        if all([all_bands_paths[band] for band in [\"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"]]):\n",
    "            calculate_all_indices_landsat(aoi_folder, \n",
    "                                          all_bands_paths[\"B4\"][0], all_bands_paths[\"B5\"][0], \n",
    "                                          all_bands_paths[\"B3\"][0], all_bands_paths[\"B2\"][0], \n",
    "                                          all_bands_paths[\"B6\"][0], all_bands_paths[\"B7\"][0], \n",
    "                                          date_range, aoi)\n",
    "\n",
    "        # Deleting unnecessary files\n",
    "        for file in os.listdir(aoi_folder):\n",
    "            file_path = os.path.join(aoi_folder, file)\n",
    "            if not file.startswith(\"L8_\"):\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path, ignore_errors=True)\n",
    "\n",
    "\n",
    "# Initialize and process each area\n",
    "start_time_whole_process = datetime.datetime.now()\n",
    "\n",
    "image_paths = generate_image_paths(txt_file, base_folder)\n",
    "image_paths = find_tif_files_for_bands(image_paths)\n",
    "process_area_bands_landsat(image_paths, shp_file, output_base_folder)\n",
    "\n",
    "end_time_whole_process = datetime.datetime.now()\n",
    "elapsed_time_whole_process = (end_time_whole_process - start_time_whole_process).total_seconds() / 60\n",
    "print(f\"Total processing time: {elapsed_time_whole_process} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161265b4-8fac-4fc4-9214-ae34ae61967c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
