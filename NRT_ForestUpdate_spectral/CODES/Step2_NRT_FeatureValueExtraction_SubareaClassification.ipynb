{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838f8ea4-c6df-4e32-9d2e-94111d2c7d31",
   "metadata": {},
   "source": [
    "# Performing land cover predictions using the Random Forest model for subareas\n",
    "\n",
    "    For each folder containing calculated spectral indices for a given subarea, the following is performed:\n",
    "\n",
    "    - Reading values ​​from spectral indices for grid points - saving as csv\n",
    "    - prediction of land cover classes usinRandom Forest e model closest to the date savinged as csv\n",
    "    - changing the csv file to a tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f11292-1951-47bd-a055-4f0fd8a30c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import rasterio\n",
    "import gc\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from geocube.api.core import make_geocube\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n",
    "\n",
    "shp_folder = '/path/to/grid_points_subareas_folder/grid_points_subareas.shp'\n",
    "base_tif_folder = '/path/to/output_files_location/sentinel2'\n",
    "output_csv_folder = '/path/to/save_output_files/sentinel2'\n",
    "model_folder = '/path/to/random_forest_models/'\n",
    "\n",
    "# Function to extract data from shapefile and TIF folders, process them, and save as CSVs\n",
    "def extract_data(shp_folder, base_tif_folder, output_csv_folder):\n",
    "    if not os.path.exists(output_csv_folder):\n",
    "        os.makedirs(output_csv_folder)\n",
    "        print(\"Output folder created:\", output_csv_folder)\n",
    "    else:\n",
    "        print(\"Output folder already exists:\", output_csv_folder)\n",
    "\n",
    "    # Function to get values from raster files\n",
    "    def get_raster_values(tif_file, coords):\n",
    "        with rasterio.open(tif_file) as src:\n",
    "            values = [x[0] for x in src.sample(coords)]\n",
    "        return values\n",
    "\n",
    "    tif_folders = os.listdir(base_tif_folder)\n",
    "\n",
    "    area_names = {'_'.join(folder.split('_')[:2]) for folder in tif_folders}\n",
    "    print(f\"Found {len(area_names)} full area names in TIF folders.\")\n",
    "\n",
    "    for area_name in area_names:\n",
    "        shp_file = os.path.join(shp_folder, area_name + \".shp\")\n",
    "        if not os.path.exists(shp_file):\n",
    "            print(f\"No SHP file for area {area_name}.\")\n",
    "            continue\n",
    "            \n",
    "        gc.collect()\n",
    "\n",
    "        grid_df = gpd.read_file(shp_file)\n",
    "        print(f\"Wczytano plik SHP: {shp_file}\")\n",
    "\n",
    "        # Match TIF folders to SHP area\n",
    "        tif_folders_for_area = [os.path.join(base_tif_folder, folder) for folder in tif_folders if folder.startswith(area_name + \"_\")]\n",
    "\n",
    "        if not tif_folders_for_area:\n",
    "            print(f\"No TIF folders for area {area_name}\")\n",
    "            continue\n",
    "\n",
    "        for tif_folder in tif_folders_for_area:\n",
    "            tif_files = [os.path.join(tif_folder, file) for file in os.listdir(tif_folder) if file.endswith(\".tif\")]\n",
    "            tif_files_sorted = sorted(tif_files)\n",
    "\n",
    "            for tif_file in tif_files_sorted:\n",
    "                column_name = os.path.splitext(os.path.basename(tif_file))[0]\n",
    "                coord_list = [(x, y) for x, y in zip(grid_df[\"geometry\"].x, grid_df[\"geometry\"].y)]\n",
    "                grid_df[column_name] = get_raster_values(tif_file, coord_list)\n",
    "\n",
    "            grid_df_cleaned = grid_df.dropna()\n",
    "            grid_df_cleaned = grid_df_cleaned[(grid_df_cleaned != 0).all(axis=1)]\n",
    "\n",
    "            new_column_names = {}\n",
    "            for col in grid_df_cleaned.columns:\n",
    "                if col.startswith(\"S2_\"):\n",
    "                    new_name = col[:3] + col[11:]\n",
    "                    new_column_names[col] = new_name\n",
    "            grid_df_cleaned.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "            # Save to CSV\n",
    "            #output_csv_name = os.path.basename(tif_folder)[:-11] + \".csv\"  # S2\n",
    "            output_csv_name = os.path.basename(tif_folder) + \".csv\"  # L8\n",
    "            output_csv_path = os.path.join(output_csv_folder, output_csv_name)\n",
    "            grid_df_cleaned.to_csv(output_csv_path, sep=\",\", index=False, header=True)\n",
    "\n",
    "            gc.collect()\n",
    "\n",
    "# Function to match the most appropriate model to the data based on dates\n",
    "def match_model_to_data(csv_file, model_folder):\n",
    "    date_pattern = re.compile(r\"\\d{4}-\\d{2}\")\n",
    "    match = date_pattern.search(csv_file)\n",
    "    if match:\n",
    "        csv_year_month = match.group()\n",
    "\n",
    "        closest_model = None\n",
    "        closest_date_diff = float('inf')\n",
    "        model_files = [f for f in os.listdir(model_folder) if f.endswith('.sav')]\n",
    "\n",
    "        for model_file in model_files:\n",
    "            model_match = date_pattern.search(model_file)\n",
    "            if model_match:\n",
    "                model_year_month = model_match.group()\n",
    "                year_diff = int(model_year_month[:4]) - int(csv_year_month[:4])\n",
    "                month_diff = int(model_year_month[5:7]) - int(csv_year_month[5:7])\n",
    "                total_month_diff = abs(year_diff * 12 + month_diff)\n",
    "\n",
    "                # Find the model with the smallest difference\n",
    "                if total_month_diff < closest_date_diff:\n",
    "                    closest_date_diff = total_month_diff\n",
    "                    closest_model = model_file\n",
    "\n",
    "        if closest_model:\n",
    "            print(f\"Matched model {closest_model} for CSV {csv_file}\")\n",
    "            return os.path.join(model_folder, closest_model)\n",
    "\n",
    "    return None\n",
    "\n",
    "# Function to perform predictions on extracted data\n",
    "def predict(model_folder, output_csv_folder):\n",
    "    csv_files = [file for file in os.listdir(output_csv_folder) if file.endswith('.csv') and file.startswith(\"AOI0\")]\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nProcessing CSV file: {csv_file}\")\n",
    "\n",
    "        csv_path = os.path.join(output_csv_folder, csv_file)\n",
    "        model_path = match_model_to_data(csv_file, model_folder)\n",
    "\n",
    "        if not model_path:\n",
    "            print(f\"No suitable model found for file {csv_file}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if df.empty:\n",
    "            print(f\"No data in file {csv_file}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        grid_gdf = gpd.GeoDataFrame(data=df, geometry=df['geometry'].apply(wkt.loads), crs=\"EPSG:32631\")\n",
    "        grid_features = df.iloc[:, 2:17]\n",
    "        inputation = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "        grid_features_filled = inputation.fit_transform(grid_features)\n",
    "        loaded_model = pickle.load(open(model_path, \"rb\"))\n",
    "        result = pd.DataFrame(loaded_model.predict(grid_features_filled))\n",
    "        df1 = pd.merge(df.iloc[:, 1], result, left_index=True, right_index=True)\n",
    "        df1.columns = [\"geometry\", \"pred_class\"]\n",
    "\n",
    "        output_csv_name = f\"predicted_{csv_file}\"\n",
    "        output_csv_path = os.path.join(output_csv_folder, output_csv_name)\n",
    "        df1.to_csv(output_csv_path, sep=\",\", index=False, header=True)\n",
    "\n",
    "# Function to convert predicted CSV files to GeoTIFF\n",
    "def convert_csv_to_geotiff(csv_folder, result_tif):\n",
    "    csv_files = [file for file in os.listdir(csv_folder) if file.startswith(\"predicted\") and file.endswith(\".csv\")]\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(csv_folder, csv_file)\n",
    "        s = time.process_time()\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            grid_prediction_gdf = gpd.GeoDataFrame(data=df, geometry=df['geometry'].apply(shapely.wkt.loads),  crs=\"EPSG:32631\")\n",
    "            csv_file_short = csv_file[10:28]  \n",
    "            geotif_file = os.path.join(result_tif, f\"Vector_classification_{csv_file_short}.tif\")\n",
    "            res = 20\n",
    "            out_grd = make_geocube(vector_data=grid_prediction_gdf, measurements=[\"pred_class\"],  resolution=(-res, res))\n",
    "\n",
    "            out_grd[\"pred_class\"].rio.to_raster(geotif_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error processing:\", csv_path)\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "# Extract data for all TIF folders\n",
    "extract_data(shp_folder, base_tif_folder, output_csv_folder)\n",
    "print(\"Data extraction completed\\n\")\n",
    "\n",
    "# Perform predictions on the extracted data\n",
    "predict(model_folder, output_csv_folder)\n",
    "print(\"Predictions completed\\n\")\n",
    "\n",
    "convert_csv_to_geotiff(output_csv_folder, output_csv_folder)\n",
    "print(\"Convert to tif completed\\n\")\n",
    "              \n",
    "print(\"Total processing time in minutes:\", (time.process_time() - start) / 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
